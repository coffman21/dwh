{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_path = \"/user/k.haritonov/data/trainDemography\"\n",
    "country_data_path = \"/user/k.haritonov/data/geography/countries.csv\"\n",
    "current_dt = \"2019-05-01\"\n",
    "output_path = \"/user/k_haritonov/hometask_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes\n",
    "df_demog = spark.read.load(user_data_path, \n",
    "                     format=\"csv\", sep=\"\\t\", header=False, inferSchema=True)\n",
    "df_countries = spark.read.load(country_data_path, \n",
    "                     format=\"csv\", sep=\",\", header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined aggregate function (UDAF) for extracting age from _c2 column.\n",
    "\n",
    "# Parse date to datetime type variable\n",
    "curr_datetime = datetime.strptime(current_dt, \"%Y-%m-%d\")\n",
    "\n",
    "# Calculate age from days passed from 1.1.1970\n",
    "def calc_age(days_from_1970):\n",
    "    # if value was None, then return None\n",
    "    if (days_from_1970 is None): return None\n",
    "    # convert to timedelta type\n",
    "    delta = timedelta(days_from_1970)\n",
    "    # calculate date of birth using datetime type\n",
    "    date_of_birth = datetime(1970, 1, 1) + delta\n",
    "    # age should be diff between current year and born year\n",
    "    age = curr_datetime.year - date_of_birth.year\n",
    "    # if day and month of date of birth was later than day and month of current date - then return age\n",
    "    if (date_of_birth.month <= curr_datetime.month and date_of_birth.day <= curr_datetime.day):\n",
    "        return age\n",
    "    # otherwise subtract 1 year\n",
    "    else:\n",
    "        return age - 1\n",
    "\n",
    "udaf_age = F.udf(calc_age, T.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alias dataframe for using in further join.\n",
    "\n",
    "# Add age from UDAF created earlier\n",
    "# Group by country ID\n",
    "# count user_IDs and select as user_cnt\n",
    "# calculate average of 'age' column, truncate decimal and rename column\n",
    "# count rows where '_c3' value is 1 (male) or 2 (female)\n",
    "\n",
    "# Then add new columns from previously created:\n",
    "# divide amount of men by amount of all users, then truncate, same for female\n",
    "\n",
    "# remove column with user IDs and add alias to dataframe\n",
    "\n",
    "dmg = df_demog.withColumn('age', udaf_age(F.col('_c2'))) \\\n",
    ".groupby('_c4').agg( \\\n",
    "        F.count(F.col('_c0')).alias('user_cnt'), \\\n",
    "        F.format_number(F.avg(F.col('age')), 2).alias('age_avg'), \\\n",
    "        F.count(F.when(F.col('_c3') == 1, True)).alias('men_cnt'), \\\n",
    "        F.count(F.when(F.col('_c3') == 2, True)).alias('wmn_cnt'), \\\n",
    ") \\\n",
    ".withColumn('men_share', F.format_number(F.col('men_cnt')/F.col('user_cnt'), 2)) \\\n",
    ".withColumn('wmn_share', F.format_number(F.col('wmn_cnt')/F.col('user_cnt'), 2)) \\\n",
    ".drop('_c0') \\\n",
    ".alias('dmg') \n",
    "\n",
    "\n",
    "# Join created dataframe with countries.\n",
    "\n",
    "# join by country ID\n",
    "# select country name, not its ID from countries dataframe , \n",
    "# and all columns from previously created dataframe\n",
    "# and remove column with country ID which was used when joining\n",
    "df_homework_1 = dmg \\\n",
    ".join(df_countries, dmg._c4 == df_countries._c0) \\\n",
    ".select(df_countries._c1.alias('country_name'), dmg['*']) \\\n",
    ".drop('_c4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to HDFS\n",
    "# Sort data by partitions and save to .csv file with overwrite mode\n",
    "df_homework_1 \\\n",
    "    .sortWithinPartitions(F.desc('user_cnt')) \\\n",
    "    .write.save(output_path, format='csv', sep='\\t', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
