{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_path = \"/user/k.haritonov/data/trainDemography\"\n",
    "country_data_path = \"/user/k.haritonov/data/geography/countries.csv\"\n",
    "current_dt = \"2019-05-01\"\n",
    "output_path = \"/user/k_haritonov/hometask_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes\n",
    "df_demog = spark.read.load(user_data_path, \n",
    "                     format=\"csv\", sep=\"\\t\", header=False, inferSchema=True)\n",
    "df_countries = spark.read.load(country_data_path, \n",
    "                     format=\"csv\", sep=\",\", header=False, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined aggregate function (UDAF) for extracting date of birth from _c2 column.\n",
    "\n",
    "# Parse date to datetime type variable\n",
    "curr_datetime = datetime.strptime(current_dt, \"%Y-%m-%d\")\n",
    "# Calculate amount of days between curr_datetime and January, 1st, 1970\n",
    "diff_days = (curr_datetime - datetime(1970, 1, 1)).days\n",
    "\n",
    "# when subtract, we found amount of days from date of bitrh of person till curr_datetime\n",
    "# when divided by 365, we found persons' age\n",
    "# if value was None, then return None, orherwise return age\n",
    "udaf_age = F.udf(lambda x: (diff_days - x)/365 if x is not None else None , IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alias dataframe for using in further join.\n",
    "\n",
    "# Add age from UDAF created earlier\n",
    "# Group by country ID\n",
    "# count user_IDs and select as user_cnt\n",
    "# calculate average of 'age' column, truncate decimal and rename column\n",
    "# count rows where '_c3' value is 1 (male) or 2 (female)\n",
    "\n",
    "# Then add new columns from previously created:\n",
    "# divide amount of men by amount of all users, then truncate, same for female\n",
    "\n",
    "# remove column with user IDs and add alias to dataframe\n",
    "\n",
    "dmg = df_demog.withColumn('age', udaf_age(F.col('_c2'))) \\\n",
    ".groupby('_c4').agg( \\\n",
    "        F.count(F.col('_c0')).alias('user_cnt'), \\\n",
    "        F.format_number(F.avg(F.col('age')), 2).alias('age_avg'), \\\n",
    "        F.count(F.when(F.col('_c3') == 1, True)).alias('men_cnt'), \\\n",
    "        F.count(F.when(F.col('_c3') == 2, True)).alias('wmn_cnt'), \\\n",
    ") \\\n",
    ".withColumn('men_share', F.format_number(F.col('men_cnt')/F.col('user_cnt'), 2)) \\\n",
    ".withColumn('wmn_share', F.format_number(F.col('wmn_cnt')/F.col('user_cnt'), 2)) \\\n",
    ".drop('_c0') \\\n",
    ".alias('dmg') \n",
    "\n",
    "\n",
    "# Join created dataframe with countries.\n",
    "\n",
    "# join by country ID\n",
    "# select country name, not its ID from countries dataframe , \n",
    "# and all columns from previously created dataframe\n",
    "# and remove column with country ID which was used when joining\n",
    "df_homework_1 = dmg \\\n",
    ".join(df_countries, dmg._c4 == df_countries._c0) \\\n",
    ".select(df_countries._c1.alias('country_name'), dmg['*']) \\\n",
    ".drop('_c4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to HDFS\n",
    "# Sort data by partitions and save to .csv file with overwrite mode\n",
    "df_homework_1 \\\n",
    "    .sortWithinPartitions(F.desc('user_cnt')) \\\n",
    "    .write.save(output_path, format='csv', sep='\\t', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
