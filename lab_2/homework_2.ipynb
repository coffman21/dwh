{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "top_year = \"1992\"\n",
    "output_path = \"/user/k_haritonov/hometask_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-----------+\n",
      "|       database|tableName|isTemporary|\n",
      "+---------------+---------+-----------+\n",
      "|tpch_flat_orc_2| customer|      false|\n",
      "|tpch_flat_orc_2| lineitem|      false|\n",
      "|tpch_flat_orc_2|   nation|      false|\n",
      "|tpch_flat_orc_2|   orders|      false|\n",
      "|tpch_flat_orc_2|     part|      false|\n",
      "|tpch_flat_orc_2| partsupp|      false|\n",
      "|tpch_flat_orc_2|   region|      false|\n",
      "|tpch_flat_orc_2| supplier|      false|\n",
      "+---------------+---------+-----------+"
     ]
    }
   ],
   "source": [
    "#Необходимо за выбранный год top_year найти top_n записей покупателей с самым большим количеством (уникальных) заказов.\n",
    "#\n",
    "#top_year - год top_dt\n",
    "#row_number - номер строки (1 строка - покупатель с самым большим колиством заказов)\n",
    "#customer_name\n",
    "#customer_nation_name\n",
    "#customer_region_name\n",
    "#orders_count - количество заказов в день date\n",
    "\n",
    "spark.sql(\"show tables in tpch_flat_orc_2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = spark.read.table(\"tpch_flat_orc_2.customer\")\n",
    "orders = spark.read.table(\"tpch_flat_orc_2.orders\")\n",
    "nation = spark.read.table(\"tpch_flat_orc_2.nation\")\n",
    "region = spark.read.table(\"tpch_flat_orc_2.region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter orders by date and limit\n",
    "top_orders = orders \\\n",
    ".filter((orders.o_orderdate > top_year) \n",
    "      & (orders.o_orderdate < str(int(top_year)+1))) \\\n",
    ".groupby(orders.o_custkey) \\\n",
    ".agg(F.count(orders.o_custkey).alias('count_orders')) \\\n",
    ".orderBy(F.col('count_orders'), ascending=False) \\\n",
    ".limit(top_n) \\\n",
    ".alias('top_orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with customer\n",
    "orders_customers = top_orders \\\n",
    ".join(customer, top_orders.o_custkey == customer.c_custkey) \\\n",
    ".alias('orders_customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with nations\n",
    "orders_customers_nation = orders_customers \\\n",
    ".join(nation, orders_customers.c_nationkey == nation.n_nationkey) \\\n",
    ".alias('orders_customers_nation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with customer, then add year and row_number columns, rename columns and select only needed\n",
    "df_homework_2 = orders_customers_nation \\\n",
    ".join(region, orders_customers_nation.n_regionkey == region.r_regionkey) \\\n",
    ".withColumn('top_year', F.lit(top_year)) \\\n",
    ".withColumn('row_number', F.row_number().over(Window.orderBy(orders_customers_nation.count_orders.desc()))) \\\n",
    ".withColumnRenamed('c_name', 'customer_name') \\\n",
    ".withColumnRenamed('n_name', 'customer_nation_name') \\\n",
    ".withColumnRenamed('r_name', 'customer_region_name') \\\n",
    ".select(*['top_year', 'row_number', 'customer_name', 'customer_nation_name', 'customer_region_name', 'count_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to HDFS\n",
    "# Sort data by partitions and save to .csv file with overwrite mode\n",
    "df_homework_2 \\\n",
    "    .repartition(1) \\\n",
    "    .write.save(output_path, format='csv', sep='\\t', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
